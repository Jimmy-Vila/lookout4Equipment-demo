{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Amazon Lookout for Equipment** - Demonstration on an anonymized expander dataset\n",
    "*Part 3: Model training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'l4e-lookout-equipment-demo2'\n",
    "PREFIX = 'data4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook configuration update\n",
    "Amazon Lookout for Equipment being a very recent service, we need to make sure that we have access to the latest version of the AWS Python packages. If you see a `pip` dependency error, check that the `boto3` version is ok: if it's greater than 1.17.48 (the first version that includes the `lookoutequipment` API), you can discard this error and move forward with the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3 version: 1.17.96 (should be >= 1.17.48 to include Lookout for Equipment API)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import boto3\n",
    "print(f'boto3 version: {boto3.__version__} (should be >= 1.17.48 to include Lookout for Equipment API)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Helper functions for managing Lookout for Equipment API calls:\n",
    "sys.path.append('../utils')\n",
    "import lookout_equipment_utils as lookout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATA       = os.path.join('..', 'data')\n",
    "LABEL_DATA = os.path.join(DATA, 'labelled-data')\n",
    "TRAIN_DATA = os.path.join(DATA, 'training-data', 'expander')\n",
    "\n",
    "ROLE_ARN = \"arn:aws:iam::831520308310:role/l4e-role\"\n",
    "REGION_NAME = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our previous analysis, we will use the following time ranges:\n",
    "\n",
    "* **Train set:** 1st January 2015 - 31st August 2015: Lookout for Equipment needs at least 180 days of training data. March is one of the anomaly period tagged in the label, so this should not change the modeling behaviour.\n",
    "* **Test set:** 1st September 2015 - 30th November 2015 *(this test set should include both normal and abnormal data to evaluate our model on)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training period: from 2015-01-01 00:00:00 to 2015-08-31 23:59:00\n",
      "Evaluation period: from 2015-09-01 00:00:00 to 2015-11-30 23:59:00\n",
      "Dataset used: lookout-demo-training-dataset\n"
     ]
    }
   ],
   "source": [
    "# Loading time ranges:\n",
    "timeranges_fname = os.path.join(DATA, 'timeranges.txt')\n",
    "with open(timeranges_fname, 'r') as f:\n",
    "    timeranges = f.readlines()\n",
    "    \n",
    "training_start   = pd.to_datetime(timeranges[0][:-1])\n",
    "training_end     = pd.to_datetime(timeranges[1][:-1])\n",
    "evaluation_start = pd.to_datetime(timeranges[2][:-1])\n",
    "evaluation_end   = pd.to_datetime(timeranges[3][:-1])\n",
    "\n",
    "print(f'Training period: from {training_start} to {training_end}')\n",
    "print(f'Evaluation period: from {evaluation_start} to {evaluation_end}')\n",
    "\n",
    "dataset_fname = os.path.join(DATA, 'dataset_name.txt')\n",
    "with open(dataset_fname, 'r') as f:\n",
    "    DATASET_NAME = f.readline()\n",
    "    \n",
    "print('Dataset used:', DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the model parameters:\n",
    "lookout_model = lookout.LookoutEquipmentModel(model_name='lookout-demo-model-v1',\n",
    "                                              dataset_name=DATASET_NAME,\n",
    "                                              region_name=REGION_NAME)\n",
    "\n",
    "# Set the training / evaluation split date:\n",
    "lookout_model.set_time_periods(evaluation_start,\n",
    "                               evaluation_end,\n",
    "                               training_start,\n",
    "                               training_end)\n",
    "\n",
    "# Set the label data location:\n",
    "lookout_model.set_label_data(bucket=BUCKET, \n",
    "                             prefix=f'{PREFIX}/labelled-data/',\n",
    "                             access_role_arn=ROLE_ARN)\n",
    "\n",
    "# This sets up the rate the service will resample the data before \n",
    "# training:\n",
    "lookout_model.set_target_sampling_rate(sampling_rate='PT5M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelArn': 'arn:aws:lookoutequipment:eu-west-1:831520308310:model/lookout-demo-model-v1/2fbe82e9-f7fe-45d1-9b66-622382bd1eda',\n",
       " 'Status': 'IN_PROGRESS',\n",
       " 'ResponseMetadata': {'RequestId': 'b3b70afd-8f7b-45dd-9f85-aa1084369097',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'b3b70afd-8f7b-45dd-9f85-aa1084369097',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '150',\n",
       "   'date': 'Thu, 17 Jun 2021 15:18:39 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actually create the model and train it:\n",
    "lookout_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-17 17:19:42 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:20:42 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:21:42 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:22:43 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:23:43 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:24:43 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:25:43 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:26:43 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:27:43 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:28:44 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:29:44 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:30:44 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:31:45 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:32:45 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:33:45 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:34:45 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:35:45 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:36:45 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:37:45 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:38:46 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:39:46 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:40:46 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:41:46 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:42:46 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:43:47 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:44:47 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:45:47 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:46:47 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:47:47 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:48:48 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:49:48 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:50:48 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:51:48 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:52:48 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:53:49 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:54:49 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:55:49 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:56:49 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:57:49 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:58:49 | Model training: IN_PROGRESS\n",
      "2021-06-17 17:59:50 | Model training: IN_PROGRESS\n",
      "2021-06-17 18:00:50 | Model training: IN_PROGRESS\n",
      "2021-06-17 18:01:50 | Model training: IN_PROGRESS\n",
      "2021-06-17 18:02:50 | Model training: IN_PROGRESS\n",
      "2021-06-17 18:03:50 | Model training: IN_PROGRESS\n",
      "2021-06-17 18:04:50 | Model training: IN_PROGRESS\n",
      "2021-06-17 18:05:51 | Model training: IN_PROGRESS\n",
      "2021-06-17 18:06:51 | Model training: IN_PROGRESS\n",
      "2021-06-17 18:07:51 | Model training: IN_PROGRESS\n",
      "2021-06-17 18:08:53 | Model training: IN_PROGRESS\n",
      "2021-06-17 18:09:55 | Model training: SUCCESS\n"
     ]
    }
   ],
   "source": [
    "lookout_model.poll_model_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---\n",
    "In this notebook, we use the dataset created in part 2 of this notebook series and trained a Lookout for Equipment model.\n",
    "\n",
    "From here you can either head:\n",
    "* To the next notebook where we will **extract the evaluation data** for this model and use it to perform further analysis on the model results.\n",
    "* Or to the **inference scheduling notebook** where we will start the model, feed it some new data and catch the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
